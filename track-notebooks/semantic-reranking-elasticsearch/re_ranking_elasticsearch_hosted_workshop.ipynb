{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*Reranking with a locally hosted reranker model from HuggingFace*"
      ],
      "metadata": {
        "id": "bW9q8qD_bPhY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup the notebook"
      ],
      "metadata": {
        "id": "BecBOzyDbWik"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install required libs"
      ],
      "metadata": {
        "id": "6ayhDP72bZAe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Xz9uWQFbNkH"
      },
      "outputs": [],
      "source": [
        "!pip install -qqU elasticsearch\n",
        "!pip install -qqU eland[pytorch]\n",
        "!pip install -qqU datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the required python libraries"
      ],
      "metadata": {
        "id": "LgHQaJh0bmJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from elasticsearch import Elasticsearch, helpers, exceptions\n",
        "from urllib.request import urlopen\n",
        "from getpass import getpass\n",
        "import json\n",
        "import time\n",
        "from datasets import load_dataset\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "CsL466H0bjNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create an Elasticsearch Python client\n",
        "\n"
      ],
      "metadata": {
        "id": "gsQ4XIpkbpd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es_url=\"http://kubernetes-vm:9200\"\n",
        "es_user=\"elastic\"\n",
        "es_pass=\"changeme\"\n",
        "\n",
        "es = Elasticsearch(\n",
        "    hosts = [es_url],\n",
        "    basic_auth=(es_user, es_pass)\n",
        ")\n",
        "\n",
        "try:\n",
        "    es.info()\n",
        "    print(\"Successfully connected to Elasticsearch!\")\n",
        "except exceptions.ConnectionError as e:\n",
        "    print(f\"Error connecting to Elasticsearch: {e}\")"
      ],
      "metadata": {
        "id": "UY5WCB0HUVTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ready Elasticsearch"
      ],
      "metadata": {
        "id": "jQdzhNbB_e3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hugging Face Reranking Model\n",
        "Run this cell to:\n",
        "- Use Eland's `eland_import_hub_model` command to upload the reranking model to Elasticsearch.\n",
        "\n",
        "For this example we've chosen the [`cross-encoder/ms-marco-MiniLM-L-6-v2`](https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2) text similarity model.\n",
        "<br><br>\n",
        "**Note**:\n",
        "While we are importing the model for use as a reranker, Eland and Elasticsearch do not have a dedicated rerank task type, so we still use `text_similarity`"
      ],
      "metadata": {
        "id": "5bsLLnqCfNKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
        "\n",
        "!eland_import_hub_model \\\n",
        "  --url $es_url \\\n",
        "  -u $es_user \\\n",
        "  -p $es_pass \\\n",
        "  --hub-model-id $model_id \\\n",
        "  --task-type text_similarity"
      ],
      "metadata": {
        "id": "J2MTEYrUfk9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Inference Endpoint\n",
        "Run this cell to:\n",
        "- Create an inference Endpoint\n",
        "- Deploy the reranking model we impoted in the previous section\n",
        "We need to create an endpoint queries can use for reranking\n",
        "\n",
        "Key points about the `model_config`\n",
        "- `service` - in this case `elasticsearch` will tell the inference API to use a locally hosted (in Elasticsearch) model\n",
        "- `num_allocations` sets the number of allocations to 1\n",
        "    - Allocations are independent units of work for NLP tasks. Scaling this allows for an increase in concurrent throughput\n",
        "- `num_threads` - sets the number of threads per allocation to 1\n",
        "    - Threads per allocation affect the number of threads used by each allocation during inference. Scaling this generally increased the speed of inference requests (to a point).\n",
        "- `model_id` - This is the id of the model as it is named in Elasticsearch\n",
        "\n"
      ],
      "metadata": {
        "id": "-rrQV6SAgWz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_config = {\n",
        "    \"service\": \"elasticsearch\",\n",
        "    \"service_settings\": {\n",
        "        \"num_allocations\": 1,\n",
        "        \"num_threads\": 1,\n",
        "        \"model_id\": \"cross-encoder__ms-marco-minilm-l-6-v2\",\n",
        "    },\n",
        "    \"task_settings\": {\"return_documents\": True},\n",
        "}\n",
        "\n",
        "inference_id = \"semantic-reranking\"\n",
        "\n",
        "create_endpoint = es.inference.put(\n",
        "    inference_id=inference_id, task_type=\"rerank\", body=model_config\n",
        ")\n",
        "\n",
        "create_endpoint.body"
      ],
      "metadata": {
        "id": "Abu084BYgWCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Verify it was created\n",
        "\n",
        "- Run the two cells in this section to verify:\n",
        "- The Inference Endpoint has been completed\n",
        "- The model has been deployed\n",
        "\n",
        "You should see JSON output with information about the semantic endpoint"
      ],
      "metadata": {
        "id": "X8rQXMrHhMkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check_endpoint = es.inference.get(\n",
        "    inference_id=inference_id,\n",
        ")\n",
        "\n",
        "check_endpoint.body"
      ],
      "metadata": {
        "id": "n3Yk7rgYhP-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the index mapping\n",
        "\n",
        "We are going to index the `title` and `abstract` from the dataset.  "
      ],
      "metadata": {
        "id": "4vqimyNWAhWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"arxiv-papers\"\n",
        "\n",
        "index_mapping = {\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\"title\": {\"type\": \"text\"}, \"abstract\": {\"type\": \"text\"}}\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "try:\n",
        "    es.indices.create(index=index_name, body=index_mapping)\n",
        "    print(f\"Index '{index_name}' created successfully.\")\n",
        "except exceptions.RequestError as e:\n",
        "    if e.error == \"resource_already_exists_exception\":\n",
        "        print(f\"Index '{index_name}' already exists.\")\n",
        "    else:\n",
        "        print(f\"Error creating index '{index_name}': {e}\")"
      ],
      "metadata": {
        "id": "DPADF_7ytTmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ready the dataset\n",
        "We are going to use the [CShorten/ML-ArXiv-Papers](https://huggingface.co/datasets/CShorten/ML-ArXiv-Papers) dataset."
      ],
      "metadata": {
        "id": "FqQmaT5P-Nhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Dataset\n",
        "**Note** You may get a warking *The secret `HF_TOKEN` does not exist in your Colab secrets*.\n",
        "\n",
        "You can safely ignore this."
      ],
      "metadata": {
        "id": "aN0dbYO7oB47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"CShorten/ML-ArXiv-Papers\")"
      ],
      "metadata": {
        "id": "IVnpj5bBoEBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Index into Elasticsearch\n",
        "\n",
        "We will loop through the dataset and send batches of rows to Elasticsearch\n",
        "- This may take a couple minutes depending on your cluster sizing."
      ],
      "metadata": {
        "id": "GQxDITCpAKWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bulk_insert_elasticsearch(dataset, index_name, chunk_size=1000):\n",
        "    actions = []\n",
        "    for record in dataset:\n",
        "        action = {\n",
        "            \"_index\": index_name,\n",
        "            \"_source\": {\"title\": record[\"title\"], \"abstract\": record[\"abstract\"]},\n",
        "        }\n",
        "        actions.append(action)\n",
        "\n",
        "        if len(actions) == chunk_size:\n",
        "            helpers.bulk(es, actions)\n",
        "            actions = []\n",
        "\n",
        "    if actions:\n",
        "        helpers.bulk(es, actions)\n",
        "\n",
        "\n",
        "bulk_insert_elasticsearch(dataset[\"train\"], index_name)"
      ],
      "metadata": {
        "id": "tDZ0qEbW-ozW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query with Reranking\n",
        "\n",
        "This containes a `text_similarity_reranker` retriever which:\n",
        "1. Uses a Standard Retriever to :\n",
        "    1. Perform a lexical query against `title field\n",
        "2. Perform a reranking:\n",
        "    1. Taks as input the top 100 results from the previous search\n",
        "      - `\"rank_window_size\": 100`\n",
        "    2. Taks as input the query\n",
        "      - `\"inference_text\": query`\n",
        "    3.  Uses our previously created reranking API and model\n"
      ],
      "metadata": {
        "id": "2bwvzLfRjJ2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"sparse vector embedding\"\n",
        "\n",
        "# Query scored from score\n",
        "response_scored = es.search(\n",
        "    index=\"arxiv-papers\",\n",
        "    body={\n",
        "        \"size\": 10,\n",
        "        \"retriever\": {\"standard\": {\"query\": {\"match\": {\"title\": query}}}},\n",
        "        \"fields\": [\"title\", \"abstract\"],\n",
        "        \"_source\": False,\n",
        "    },\n",
        ")\n",
        "\n",
        "# Query with Semantic Reranker\n",
        "response_reranked = es.search(\n",
        "    index=\"arxiv-papers\",\n",
        "    body={\n",
        "        \"size\": 10,\n",
        "        \"retriever\": {\n",
        "            \"text_similarity_reranker\": {\n",
        "                \"retriever\": {\"standard\": {\"query\": {\"match\": {\"title\": query}}}},\n",
        "                \"field\": \"abstract\",\n",
        "                \"inference_id\": \"semantic-reranking\",\n",
        "                \"inference_text\": query,\n",
        "                \"rank_window_size\": 100,\n",
        "            }\n",
        "        },\n",
        "        \"fields\": [\"title\", \"abstract\"],\n",
        "        \"_source\": False,\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "HWXQBS35jQ3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print the table comparing the scored and reranked results"
      ],
      "metadata": {
        "id": "Hnam80Irbj6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titles_scored = [\n",
        "    paper[\"fields\"][\"title\"][0] for paper in response_scored.body[\"hits\"][\"hits\"]\n",
        "]\n",
        "titles_reranked = [\n",
        "    paper[\"fields\"][\"title\"][0] for paper in response_reranked.body[\"hits\"][\"hits\"]\n",
        "]\n",
        "\n",
        "# Creating a DataFrame\n",
        "df = pd.DataFrame(\n",
        "    {\"Scored Results\": titles_scored, \"Reranked Results\": titles_reranked}\n",
        ")\n",
        "\n",
        "df_styled = df.style.set_properties(**{\"text-align\": \"left\"}).set_caption(\n",
        "    f\"Comparison of Scored and Semantic Reranked Results - Query: '{query}'\"\n",
        ")\n",
        "\n",
        "# Display the table\n",
        "df_styled"
      ],
      "metadata": {
        "id": "yTTNYCYcBtll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print out Title and Abstract\n",
        "This will print the title and the abstract for the top 10 results after semantic reranking."
      ],
      "metadata": {
        "id": "A0HyNZoWyeun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for paper in response_scored.body[\"hits\"][\"hits\"]:\n",
        "    print(\n",
        "        f\"Title {paper['fields']['title'][0]} \\n  Abstract: {paper['fields']['abstract'][0]}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "4ZEx-46rn3in"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}