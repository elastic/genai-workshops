{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Locally Hosted Semantic Reranker**"
      ],
      "metadata": {
        "id": "bW9q8qD_bPhY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objectives\n",
        "\n",
        "In this challenge you will:\n",
        "- Learn how to load a semantic reranker into Elasticsearch with Eland\n",
        "- Create a reranker inference API\n",
        "- Modify the query to use the reranker as part of the query to gather contextual documents"
      ],
      "metadata": {
        "id": "Mf09mgBb5Bb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## If this is your first time using Jupyter notebook:\n",
        "\n",
        "<img src=\"https://play.instruqt.com/assets/tracks/xh4efwjkleh1/9de47748dceadc1b6546908519ea4ba6/assets/CleanShot%202024-09-12%20at%2014.06.51%402x.png\" width=\"150\"/>\n",
        "Click the small play icon to the left of the cell<br>\n",
        "\n",
        "<img src=\"https://play.instruqt.com/assets/tracks/xh4efwjkleh1/f7949234f997ba39ff8879304648efaa/assets/CleanShot%202024-09-12%20at%2014.07.22%402x.png\" width=\"150\"/>\n",
        "If the cell runs successfully you will see a green check markt at the bottom left in the cell<br>\n",
        "\n",
        "<img src=\"https://play.instruqt.com/assets/tracks/xh4efwjkleh1/0fd068121e9d48f13b49d8e02a21fe42/assets/CleanShot%202024-09-12%20at%2014.09.32%402x.png\" width=\"150\"/>\n",
        "If there is an error, you will see a red x and may see error output below"
      ],
      "metadata": {
        "id": "hn5LrtoIrzBs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "Run the cells in this section to:\n",
        "- Import the required libraries\n",
        "- Create an elasticsearch python client connection\n"
      ],
      "metadata": {
        "id": "BecBOzyDbWik"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These should already be installed in your notebook environment.\n",
        "You can uncomment and run if needed"
      ],
      "metadata": {
        "id": "6ayhDP72bZAe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Xz9uWQFbNkH"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU elasticsearch\n",
        "#!pip install -qU eland[pytorch]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the required python libraries"
      ],
      "metadata": {
        "id": "LgHQaJh0bmJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from elasticsearch import Elasticsearch, helpers, exceptions\n",
        "from urllib.request import urlopen\n",
        "from getpass import getpass\n",
        "import json\n",
        "import time"
      ],
      "metadata": {
        "id": "CsL466H0bjNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an Elasticsearch Python client"
      ],
      "metadata": {
        "id": "gsQ4XIpkbpd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es = Elasticsearch(\n",
        "    hosts = [\"http://kubernetes-vm:9200\"],\n",
        "    basic_auth=(\"elastic\", \"changeme\")\n",
        ")"
      ],
      "metadata": {
        "id": "P8Pf-lDepKdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload Hugging Face model with Eland\n",
        "Run this cell to:\n",
        "- Upload the model from Hugging Face to Elasticsearch\n",
        "- Use Eland's `eland_import_hub_model` command to upload the model to Elasticsearch.\n",
        "\n",
        "For this example we've chosen the [`cross-encoder/ms-marco-MiniLM-L-6-v2`](https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2) text similarity model.\n",
        "<br><br>\n",
        "**Note**:\n",
        "While we are importing the model for use as a reranker, Eland and Elasticsearch do not have a dedicated rerank task type, so we still use `text_similarity`"
      ],
      "metadata": {
        "id": "5bsLLnqCfNKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ID = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
        "\n",
        "!eland_import_hub_model \\\n",
        "  --url \"http://kubernetes-vm:9200\" \\\n",
        "  -u \"elastic\" \\\n",
        "  -p \"changeme\" \\\n",
        "  --hub-model-id $MODEL_ID \\\n",
        "  --task-type text_similarity"
      ],
      "metadata": {
        "id": "J2MTEYrUfk9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Inference Endpoint\n",
        "Run this cell to:\n",
        "- Create an inference Endpoint\n",
        "- Deploy the reranking model we impoted in the previous section\n",
        "We need to create an endpoint queries can use for reranking\n",
        "\n",
        "Key points about the `model_config`\n",
        "- `service` - in this case `elasticsearch` will tell the inference API to use a locally hosted (in Elasticsearch) model\n",
        "- `num_allocations` sets the number of allocations to 1\n",
        "    - Allocations are independent units of work for NLP tasks. Scaling this allows for an increase in concurrent throughput\n",
        "- `num_threads` - sets the number of threads per allocation to 1\n",
        "    - Threads per allocation affect the number of threads used by each allocation during inference. Scaling this generally increased the speed of inference requests (to a point).\n",
        "- `model_id` - This is the id of the model as it is named in Elasticsearch\n",
        "\n"
      ],
      "metadata": {
        "id": "-rrQV6SAgWz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_config = {\n",
        "  \"service\": \"elasticsearch\",\n",
        "  \"service_settings\": {\n",
        "    \"num_allocations\": 1,\n",
        "    \"num_threads\": 1,\n",
        "    \"model_id\": \"cross-encoder__ms-marco-minilm-l-6-v2\"\n",
        "  },\n",
        "      \"task_settings\": {\n",
        "        \"return_documents\": True\n",
        "    }\n",
        "}\n",
        "\n",
        "inference_id = \"semantic-reranking\"\n",
        "\n",
        "create_endpoint = es.inference.put(\n",
        "    inference_id=inference_id,\n",
        "    task_type=\"rerank\",\n",
        "    body=model_config\n",
        ")\n",
        "\n",
        "create_endpoint.body"
      ],
      "metadata": {
        "id": "Abu084BYgWCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Verify it was created\n",
        "\n",
        "- Run the two cells in this section to verify:\n",
        "- The Inference Endpoint has been completed\n",
        "- The model has been deployed\n",
        "\n",
        "You should see JSON output with information about the semantic endpoint"
      ],
      "metadata": {
        "id": "X8rQXMrHhMkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check_endpoint = es.inference.get(\n",
        "    inference_id=inference_id,\n",
        ")\n",
        "\n",
        "check_endpoint.body"
      ],
      "metadata": {
        "id": "n3Yk7rgYhP-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify the model was successfully deployed\n",
        "\n",
        "The cell below should return `started`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6dqYN5B4gI7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ES_MODEL_ID = \"cross-encoder__ms-marco-minilm-l-6-v2\"\n",
        "\n",
        "model_info = es.ml.get_trained_models_stats(model_id=ES_MODEL_ID)\n",
        "\n",
        "model_info.body['trained_model_stats'][0]['deployment_stats']['nodes'][0]['routing_state']['routing_state']"
      ],
      "metadata": {
        "id": "tui0K4JIgNmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query with Reranking\n",
        "\n",
        "This containes a `text_similarity_reranker` retriever which:\n",
        "1. Uses a Standard Retriever to :\n",
        "    1. Perform a semantic query against the chunked ELSER embeddings\n",
        "    2. Return the top 2 inner hit chunks\n",
        "2. Perform a reranking:\n",
        "    1. Taks as input the top 50 results from the previous search\n",
        "      - `\"rank_window_size\": 50`\n",
        "    2. Taks as input the uer's question\n",
        "      - `\"inference_text\": USER_QUESTION`\n",
        "    3.  Uses our previously created reranking API and model\n"
      ],
      "metadata": {
        "id": "2bwvzLfRjJ2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "USER_QUESTION = \"Where can I get good pizza?\"\n",
        "\n",
        "response = es.search(\n",
        "    index=\"restaurant_reviews\",\n",
        "    body={\n",
        "      \"retriever\": {\n",
        "        \"text_similarity_reranker\": {\n",
        "          \"retriever\": {\n",
        "            \"standard\": {\n",
        "              \"query\": {\n",
        "                \"nested\": {\n",
        "                  \"path\": \"semantic_body.inference.chunks\",\n",
        "                  \"query\": {\n",
        "                    \"sparse_vector\": {\n",
        "                      \"inference_id\": \"my-elser-endpoint\",\n",
        "                      \"field\": \"semantic_body.inference.chunks.embeddings\",\n",
        "                      \"query\": USER_QUESTION\n",
        "                    }\n",
        "                  },\n",
        "                  \"inner_hits\": {\n",
        "                    \"size\": 2,\n",
        "                    \"name\": \"restaurant_reviews.semantic_body\",\n",
        "                    \"_source\": [\n",
        "                      \"semantic_body.inference.chunks.text\"\n",
        "                    ]\n",
        "                  }\n",
        "                }\n",
        "              }\n",
        "            }\n",
        "          },\n",
        "          \"field\": \"Review\",\n",
        "          \"inference_id\": \"semantic-reranking\",\n",
        "          \"inference_text\": USER_QUESTION,\n",
        "          \"rank_window_size\": 50\n",
        "        }\n",
        "      }\n",
        "    }\n",
        ")\n",
        "\n",
        "response.raw"
      ],
      "metadata": {
        "id": "HWXQBS35jQ3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print out the formatted response"
      ],
      "metadata": {
        "id": "A0HyNZoWyeun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for review in response.raw['hits']['hits']:\n",
        "    print(f\"Restaurant {review['_source']['Restaurant']} - Rating: {review['_source']['Rating']} - Reviewer: {review['_source']['Reviewer']}\")\n"
      ],
      "metadata": {
        "id": "4ZEx-46rn3in"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}